{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T11:02:47.435033900Z",
     "start_time": "2024-07-17T11:02:43.146650400Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import platform\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from utils.normalization import normalize_range, un_normalize_range\n",
    "from utils.seed import set_seed\n",
    "\n",
    "from sequential_nn.dataset import MTDataset\n",
    "from sequential_nn.model import Network\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-92edc9144581447f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-92edc9144581447f\");\n          const url = new URL(\"/\", window.location);\n          const port = 6007;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./runs --port 6007"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T11:02:47.522026500Z",
     "start_time": "2024-07-17T11:02:47.439420300Z"
    }
   },
   "id": "a3171c836c1d8ffc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2024\n",
      "Using device: cuda\n",
      "There are 20160 entries in the training dictionary\n",
      "Number of model parameters:  192302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26/150, Loss = 0.020958768855780362:  17%|█▋        | 26/150 [02:25<10:57,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved epoch 25 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 51/150, Loss = 0.018626624811440708:  34%|███▍      | 51/150 [04:43<08:50,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved epoch 50 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 76/150, Loss = 0.017742114886641503:  51%|█████     | 76/150 [06:55<06:31,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved epoch 75 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 101/150, Loss = 0.017597652785480023:  67%|██████▋   | 101/150 [09:07<04:21,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved epoch 100 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 126/150, Loss = 0.017431594710797072:  84%|████████▍ | 126/150 [11:20<02:04,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved epoch 125 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 150/150, Loss = 0.017309702653437852: 100%|██████████| 150/150 [13:24<00:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 805.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    torch.multiprocessing.freeze_support()\n",
    "    # i fucked up 'mouse_aacid_k_regular_nn_noise_005'\n",
    "    dict_name_category = '1300'  # 1300, dense, new_t\n",
    "\n",
    "    # Schedule iterations\n",
    "    # number of raw images in the CEST-MRF acquisition schedule\n",
    "    sched_iter = 30\n",
    "    add_iter = 2\n",
    "\n",
    "    # Training properties\n",
    "    learning_rate = 2e-4\n",
    "    batch_size = 1024\n",
    "    num_epochs = 150\n",
    "    noise_std = 0.01  # noise level for training, 1e-2\n",
    "\n",
    "    min_delta = 0.05  # minimum absolute change in the loss function\n",
    "    patience = np.inf\n",
    "\n",
    "    current_dir = os.getcwd()  # Get the current directory\n",
    "    parent_dir = os.path.dirname(current_dir)  # Navigate up one directory level\n",
    "    mt_dict_folder_fn = os.path.join(parent_dir, 'data', 'exp', 'mt_glu_dicts', dict_name_category, 'mt', 'MT52', 'dict.pkl')  # dict folder directory\n",
    "\n",
    "    net_name = f'noise_{noise_std}'\n",
    "    nn_fn = os.path.join(current_dir, 'mouse_nns', 'glu_mt_nns', dict_name_category, 'mt', 'MT52', f'{net_name}.pt')  # nn directory\n",
    "\n",
    "    device = initialize_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    (min_param_tensor, max_param_tensor,\n",
    "     min_water_t1t2_tensor, max_water_t1t2_tensor) = define_min_max(mt_dict_folder_fn, device)\n",
    "    \n",
    "    # Convert tensors to numpy arrays\n",
    "    min_param_array = min_param_tensor.cpu().numpy()\n",
    "    max_param_array = max_param_tensor.cpu().numpy()\n",
    "    min_water_t1t2_array = min_water_t1t2_tensor.cpu().numpy()\n",
    "    max_water_t1t2_array = max_water_t1t2_tensor.cpu().numpy()\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(nn_fn)):\n",
    "        os.makedirs(os.path.dirname(nn_fn))\n",
    "    # Save all arrays to a single .npz file\n",
    "    np.savez(os.path.join(os.path.dirname(nn_fn),'min_max_values.npz'),\n",
    "             min_param=min_param_array,\n",
    "             max_param=max_param_array,\n",
    "             min_water_t1t2=min_water_t1t2_array,\n",
    "             max_water_t1t2=max_water_t1t2_array)\n",
    "\n",
    "    # Loading the training dataset\n",
    "    # train_dataset = GluMemDataset(memmap_fn, sched_iter, add_iter, chunk_size=10000000)\n",
    "    train_dataset = MTDataset(mt_dict_folder_fn)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4)\n",
    "\n",
    "    train_network(train_loader, device, sched_iter, add_iter, learning_rate, num_epochs, noise_std, patience,\n",
    "                  min_delta, min_param_tensor, max_param_tensor, min_water_t1t2_tensor,\n",
    "                  max_water_t1t2_tensor, nn_fn)\n",
    "\n",
    "\n",
    "# Function to initialize device\n",
    "def initialize_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Function to train the network\n",
    "def train_network(train_loader, device, sched_iter, add_iter, learning_rate, num_epochs, noise_std, patience, min_delta,\n",
    "                  min_param_tensor, max_param_tensor, min_water_t1t2_tensor, max_water_t1t2_tensor, nn_fn):\n",
    "    nn_folder = os.path.dirname(nn_fn)  # Navigate up one directory level\n",
    "    if not os.path.exists(nn_folder):\n",
    "        os.makedirs(nn_folder)\n",
    "\n",
    "    # Initializing the reconstruction network\n",
    "    reco_net = Network(sched_iter, add_iter=add_iter, n_hidden=2, n_neurons=300).to(device)\n",
    "\n",
    "    # Print amount of parameters\n",
    "    print('Number of model parameters: ', sum(p.numel() for p in reco_net.parameters() if p.requires_grad))\n",
    "\n",
    "    # Setting optimizer\n",
    "    optimizer = torch.optim.Adam(reco_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "\n",
    "    # Storing current time\n",
    "    t0 = time.time()\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    loss_per_epoch = []\n",
    "    patience_counter = 0\n",
    "    min_loss = 100\n",
    "\n",
    "    reco_net.train()\n",
    "\n",
    "    pbar = tqdm.tqdm(total=num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Cumulative loss\n",
    "        cum_loss = 0\n",
    "        counter = np.nan\n",
    "\n",
    "        for counter, dict_params in enumerate(train_loader, 0):\n",
    "            reco_net, cum_loss = train_step(device, noise_std, reco_net, optimizer, cum_loss, dict_params,\n",
    "                                            min_param_tensor, max_param_tensor,\n",
    "                                            min_water_t1t2_tensor, max_water_t1t2_tensor, writer, epoch)\n",
    "            \n",
    "            del dict_params\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Average loss for this epoch\n",
    "        loss_per_epoch.append(cum_loss / (counter + 1))\n",
    "\n",
    "        pbar.set_description(f'Epoch: {epoch + 1}/{num_epochs}, Loss = {loss_per_epoch[-1]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if (min_loss - loss_per_epoch[-1]) / min_loss > min_delta:\n",
    "            min_loss = loss_per_epoch[-1]\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter > patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "        # Save model checkpoint every 25 epochs (excluding epoch 0)\n",
    "        if epoch % 25 == 0 and epoch != 0:\n",
    "            print(f\"\\nSaved epoch {epoch} model\")\n",
    "            torch.save({\n",
    "                'model_state_dict': reco_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss_per_epoch': loss_per_epoch,\n",
    "                'noise_std': noise_std,\n",
    "                'epoch': epoch\n",
    "            }, nn_fn)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    pbar.close()\n",
    "    print(f\"Training took {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Save final model checkpoint\n",
    "    torch.save({\n",
    "        'model_state_dict': reco_net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss_per_epoch': loss_per_epoch,\n",
    "        'noise_std': noise_std,\n",
    "    }, nn_fn)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    return reco_net\n",
    "\n",
    "\n",
    "def train_step(device, noise_std, reco_net, optimizer, cum_loss, dict_params, min_param_tensor, max_param_tensor,\n",
    "               min_water_t1t2_tensor, max_water_t1t2_tensor, writer, epoch):\n",
    "    cur_fs, cur_ksw, cur_t1w, cur_t2w, cur_norm_sig = dict_params\n",
    "\n",
    "    target = torch.stack((cur_fs, cur_ksw), dim=1).to(device)\n",
    "    input_water_t1t2 = torch.stack((cur_t1w, cur_t2w), dim=1).to(device)\n",
    "\n",
    "    # Normalizing the target and input_water_t1t2\n",
    "    target = normalize_range(original_array=target, original_min=min_param_tensor,\n",
    "                             original_max=max_param_tensor, new_min=0, new_max=1).to(device)\n",
    "\n",
    "    input_water_t1t2 = normalize_range(original_array=input_water_t1t2, original_min=min_water_t1t2_tensor,\n",
    "                                       original_max=max_water_t1t2_tensor, new_min=0, new_max=1).to(device)\n",
    "\n",
    "    # Adding noise to the input signals (trajectories)\n",
    "    noised_sig = cur_norm_sig + torch.randn(cur_norm_sig.size()) * noise_std\n",
    "\n",
    "    # noised_sig = noised_sig / torch.linalg.norm(noised_sig, dim=1, ord=2, keepdim=True)\n",
    "\n",
    "    # adding the mt_fs_ksw and t1, t2 as additional nn input\n",
    "    noised_sig = torch.hstack((input_water_t1t2, noised_sig.to(device))).to(device)\n",
    "    del input_water_t1t2\n",
    "\n",
    "    # Forward step\n",
    "    prediction = reco_net(noised_sig.float())\n",
    "    del noised_sig\n",
    "\n",
    "    # Batch loss (MSE)\n",
    "    loss = torch.mean((prediction.float() - target.float()) ** 2)\n",
    "    del target\n",
    "\n",
    "    # Backward step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimization step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Storing Cumulative loss\n",
    "    cum_loss += loss.item()\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", loss.item(), epoch)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return reco_net, cum_loss\n",
    "\n",
    "def define_min_max(mt_dict_fn, device):\n",
    "    dictionary = pd.read_pickle(mt_dict_fn)\n",
    "\n",
    "    min_fs = np.min(dictionary['fs_0'])  # uncomment if non-zero minimum limit is required\n",
    "    min_ksw = np.min(dictionary['ksw_0'].transpose().astype(float))  # uncomment if non-zero minimum limit needed\n",
    "    max_fs = np.max(dictionary['fs_0'])\n",
    "    max_ksw = np.max(dictionary['ksw_0'].transpose().astype(float))\n",
    "\n",
    "    min_t1w = np.min(dictionary['t1w'])\n",
    "    min_t2w = np.min(dictionary['t2w'].transpose().astype(float))\n",
    "    max_t1w = np.max(dictionary['t1w'])\n",
    "    max_t2w = np.max(dictionary['t2w'].transpose().astype(float))\n",
    "\n",
    "    min_param_tensor = torch.tensor(np.hstack((min_fs, min_ksw)), requires_grad=False).to(device)  # can be switched to  min_fs, min_ksw\n",
    "    max_param_tensor = torch.tensor(np.hstack((max_fs, max_ksw)), requires_grad=False).to(device)\n",
    "\n",
    "    min_water_t1t2_tensor = torch.tensor(np.hstack((min_t1w, min_t2w)), requires_grad=False).to(device)\n",
    "    max_water_t1t2_tensor = torch.tensor(np.hstack((max_t1w, max_t2w)), requires_grad=False).to(device)\n",
    "\n",
    "    return min_param_tensor, max_param_tensor, min_water_t1t2_tensor, max_water_t1t2_tensor\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if platform.system() == 'Windows':\n",
    "        multiprocessing.set_start_method('spawn', force=True)\n",
    "    # os.chdir(os.path.dirname(os.path.realpath(__file__)))\n",
    "    set_seed(2024)\n",
    "\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T11:16:21.095995Z",
     "start_time": "2024-07-17T11:02:47.509000600Z"
    }
   },
   "id": "c9518e7393aec66a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T11:16:21.099995300Z",
     "start_time": "2024-07-17T11:16:21.083490600Z"
    }
   },
   "id": "3f29685008ce0533",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
