{
 "cells": [
  {
   "cell_type": "code",
   "id": "51f80d20073c3aaf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T21:17:54.482367600Z",
     "start_time": "2024-06-24T21:17:52.748401700Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "from my_funcs.plot_functions import t1_t2_pixel_reader\n",
    "\n",
    "from my_funcs.cest_functions import bruker_dataset_creator\n",
    "from my_funcs.cest_functions import dicom_data_arranger\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Use GPU if available (otherwise use CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print('GPU found and will be used')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU was not found. Using CPU')\n",
    "\n",
    "sched_iter = 31\n",
    "dtype = torch.DoubleTensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T21:17:56.006099Z",
     "start_time": "2024-06-24T21:17:55.979177800Z"
    }
   },
   "id": "73261245c74b7784",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found and will be used\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## subject data ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8916f21a35b03bb6"
  },
  {
   "cell_type": "code",
   "source": [
    "from my_funcs.mouse_data_dicts import subject_dicts_june_tumor\n",
    "\n",
    "# Root stats:\n",
    "general_fn = os.path.abspath(os.curdir)\n",
    "current_dir = os.getcwd()  # Get the current directory\n",
    "parent_dir = os.path.dirname(current_dir)  # Navigate up one directory level\n",
    "\n",
    "# Subject data:\n",
    "txt_file_name = 'labarchive_notes.txt'\n",
    "save_name = 'mouse_june_tumor'\n",
    "fp_prtcl_names = ['107a']  # to be looped later with all options # 107a , 51_glu\n",
    "f_const = 3 / 110000\n",
    "\n",
    "# subject_dicts = [\n",
    "#         {'scan_name': '24_06_10_glu_old_tumor_mouse_37deg',\n",
    "#      'sub_name': '2_mouse_old_no_tumor',\n",
    "#      'month': 'june',\n",
    "#      'save_name': save_name,\n",
    "#      'center': [39, 15],\n",
    "#      'voxel_origin': [28, 13],\n",
    "#      't_shift': [0, 0],  # up, right\n",
    "#      'highres_img_idx': 0,\n",
    "#      'resratio': 2,\n",
    "#      # 'roi_center': [25, 41],\n",
    "#      'temp': 37,\n",
    "#      'z_b1s': [0.7, 1.5, 2.5],\n",
    "#      'z_b1s_names': ['0p7uT', '1p5uT', '2p5uT']  # no reverse (first instance)\n",
    "#      },\n",
    "#         {'scan_name': '24_06_10_glu_old_tumor_mouse_37deg',\n",
    "#      'sub_name': '5_mouse_old_no_tumor',\n",
    "#      'month': 'june',\n",
    "#      'save_name': save_name,\n",
    "#      'center': [39, 15],\n",
    "#      'voxel_origin': [28, 13],\n",
    "#      't_shift': [-1, -1],  # up, right\n",
    "#      'highres_img_idx': 1,\n",
    "#      'resratio': 2,\n",
    "#      'temp': 37,\n",
    "#      'z_b1s': [0.7, 1.5, 2.5],\n",
    "#      'z_b1s_names': ['0p7uT', '1p5uT', '2p5uT']  # slice matching issue\n",
    "#      },\n",
    "#         {'scan_name': '24_06_10_glu_old_tumor_mouse_37deg',\n",
    "#      'sub_name': '8_mouse_old_2R_tumor',\n",
    "#      'month': 'june',\n",
    "#      'save_name': save_name,\n",
    "#      'center': [39, 15],\n",
    "#      'voxel_origin': [28, 13],\n",
    "#      't_shift': [-1, 0],  # up, right\n",
    "#      'highres_img_idx': 1,\n",
    "#      'resratio': 2,\n",
    "#      'temp': 37,\n",
    "#      'z_b1s': [0.7, 1.5, 2.5],\n",
    "#      'z_b1s_names': ['0p7uT', '1p5uT', '2p5uT']\n",
    "#      },\n",
    "#  ]\n",
    "\n",
    "subject_dicts = subject_dicts_june_tumor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T21:17:57.395843400Z",
     "start_time": "2024-06-24T21:17:57.377517Z"
    }
   },
   "id": "50f3533a22729ef1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Choose nn ##"
   ],
   "id": "939a5ed3f1841c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.805824Z",
     "start_time": "2024-06-17T08:59:59.760946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1300-2300 t1 case\n",
    "dict_name = 'mouse_k_8500' # 'mouse_20', 'mouse_20_limited_k'\n",
    "net_name = 'mouse_k_8500_noise_01'  # [mouse_20_noise_01, 'mouse_20_noise_005'], ['mouse_20_limited_k_noise_01']\n",
    "mt_type = 1100\n",
    "glu_noise = '01'\n",
    "\n",
    "# Dict choice:\n",
    "mt_dict_fn = os.path.join(parent_dir, 'data', 'exp', f'2_seq_{mt_type}', 'mt', 'mouse_mt', 'MT52', 'dict.pkl')  # 1300-2300 t1\n",
    "glu_dict_fn = os.path.join(parent_dir, 'data', 'exp', f'2_seq_{mt_type}', 'glu', dict_name, '107a', 'dict.pkl')\n",
    "\n",
    "# NN choice:\n",
    "mt_nn_fn = os.path.join(current_dir, 'mouse_nns', 'mt_nns', f'mt_noise_01.pt') # mt nn directory (1300-2300 t1)\n",
    "glu_nn_fn = os.path.join(current_dir, 'mouse_nns', 'glu_nns', f'{dict_name}', f'{net_name}.pt')  # nn directory # 'checkpoint_107a.pt'\n"
   ],
   "id": "546ef00d01a582a1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## choose scan ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ff71f3ae14b3fee"
  },
  {
   "cell_type": "code",
   "source": [
    "fp_prtcl_name = fp_prtcl_names[0]\n",
    "subject_i = 0\n",
    "\n",
    "subject_dict = subject_dicts[subject_i]\n",
    "phantom_choice = subject_i+1\n",
    "glu_mouse_fn = os.path.join(parent_dir, 'data', 'scans', subject_dict['scan_name'], subject_dict['sub_name'])\n",
    "\n",
    "glu_107a_fn, glu_mouse_mrf_files_fn, bruker_dataset_107a = bruker_dataset_creator(glu_mouse_fn, txt_file_name, '107a')\n",
    "mt_25_fn, _, bruker_dataset_52 = bruker_dataset_creator(glu_mouse_fn, txt_file_name, 'MT52')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.842668Z",
     "start_time": "2024-06-17T08:59:59.806426Z"
    }
   },
   "id": "3b23277b61d5c08",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load pre-created mask ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1082c40f780ef77e"
  },
  {
   "cell_type": "code",
   "source": [
    "mask_path = os.path.join(os.path.dirname(os.path.dirname(glu_mouse_mrf_files_fn)), 'sitk_mask.npy')\n",
    "mask = np.load(mask_path)\n",
    "subject_dict['roi_mask'] = mask\n",
    "subject_dicts['save_name'] = save_name\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.854440Z",
     "start_time": "2024-06-17T08:59:59.843206Z"
    }
   },
   "id": "59fea44a30de8fbf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# create image path #"
   ],
   "id": "adbfe3a861827ca9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.876514Z",
     "start_time": "2024-06-17T08:59:59.854983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subject_image_path = f'images/{save_name}/subject_{phantom_choice}'\n",
    "if not os.path.exists(subject_image_path):\n",
    "    os.makedirs(subject_image_path)\n",
    "\n",
    "subject_nn_image_path = os.path.join(subject_image_path, dict_name, net_name)\n",
    "if not os.path.exists(subject_nn_image_path):\n",
    "    os.makedirs(subject_nn_image_path)\n"
   ],
   "id": "b646b6bc2751533f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a9c851189c461c6"
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the acquired data\n",
    "acquired_data_52 = dicom_data_arranger(bruker_dataset_52, mt_25_fn).astype(np.float)[1:,:,:]\n",
    "[_, c_acq_data, w_acq_data] = np.shape(acquired_data_52*mask)  # mask here\n",
    "\n",
    "# Reshaping the acquired data to the shape expected by the NN (e.g. 31 x ... )\n",
    "acquired_data_52 = np.reshape(acquired_data_52, (sched_iter, c_acq_data * w_acq_data), order='F')\n",
    "\n",
    "# 2-norm normalization of the dictionary signals\n",
    "acquired_data_52 = acquired_data_52 / np.sqrt(np.sum(acquired_data_52 ** 2, axis=0))\n",
    "\n",
    "# Transposing for compatibility with the NN - now each row is a trajectory\n",
    "acquired_data_52 = acquired_data_52.T\n",
    "\n",
    "# Converting to tensor\n",
    "acquired_data_52 = Variable(torch.from_numpy(acquired_data_52).type(dtype), requires_grad=False).to(device)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.913432Z",
     "start_time": "2024-06-17T08:59:59.877117Z"
    }
   },
   "id": "83b42612e6ea2894",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the acquired data\n",
    "acquired_data_107a = dicom_data_arranger(bruker_dataset_107a, glu_107a_fn).astype(np.float)[1:,:,:]\n",
    "[_, c_acq_data, w_acq_data] = np.shape(acquired_data_107a*mask)  # mask here\n",
    "\n",
    "# Reshaping the acquired data to the shape expected by the NN (e.g. 31 x ... )\n",
    "acquired_data_107a = np.reshape(acquired_data_107a, (sched_iter, c_acq_data * w_acq_data), order='F')\n",
    "\n",
    "# 2-norm normalization of the dictionary signals\n",
    "acquired_data_107a = acquired_data_107a / np.sqrt(np.sum(acquired_data_107a ** 2, axis=0))\n",
    "\n",
    "# Transposing for compatibility with the NN - now each row is a trajectory\n",
    "acquired_data_107a = acquired_data_107a.T\n",
    "\n",
    "# Converting to tensor\n",
    "acquired_data_107 = Variable(torch.from_numpy(acquired_data_107a).type(dtype), requires_grad=False).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.940637Z",
     "start_time": "2024-06-17T08:59:59.914032Z"
    }
   },
   "id": "8108940a2af0acac",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the separately acquired water_t1t2-maps\n",
    "t1 = t1_t2_pixel_reader(glu_phantom_fn=glu_mouse_fn, txt_file_name=txt_file_name, image_idx=3, t_type='t1',\n",
    "                               image_file=4)\n",
    "t2 = t1_t2_pixel_reader(glu_phantom_fn=glu_mouse_fn, txt_file_name=txt_file_name, image_idx=3, t_type='t2')\n",
    "\n",
    "shift_up, shift_right = subject_dict['t_shift']\n",
    "t1 = np.roll(t1, shift=(shift_up, shift_right), axis=(0, 1))\n",
    "t2 = np.roll(t2, shift=(shift_up, shift_right), axis=(0, 1))\n",
    "\n",
    "masked_t1 = np.ma.masked_where(mask == 0, t1)\n",
    "masked_t2 = np.ma.masked_where(mask == 0, t2)\n",
    "\n",
    "print(f't1 min-max: [{np.min(masked_t1), np.max(masked_t1)}]')\n",
    "print(f't2 min-max: [{np.min(masked_t2), np.max(masked_t2)}]')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.950037Z",
     "start_time": "2024-06-17T08:59:59.941803Z"
    }
   },
   "id": "20748eb08ecc3291",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 min-max: [(0.0, 4147.270813839999)]\n",
      "t2 min-max: [(0.0, 2436.439002228)]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Reshaping the acquired data to the shape expected by the NN (e.g. 2 x ... )\n",
    "acquired_map_t1w_orig = t1.astype(np.float32) / 1000\n",
    "acquired_map_t2w_orig = t2.astype(np.float32) / 1000\n",
    "\n",
    "acquired_map_t1w = np.reshape(acquired_map_t1w_orig, (1, c_acq_data * w_acq_data), order='F').T\n",
    "acquired_map_t1w = torch.from_numpy(acquired_map_t1w)\n",
    "\n",
    "acquired_map_t2w = np.reshape(acquired_map_t2w_orig, (1, c_acq_data * w_acq_data), order='F').T\n",
    "acquired_map_t2w = torch.from_numpy(acquired_map_t2w)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T08:59:59.974725Z",
     "start_time": "2024-06-17T08:59:59.950507Z"
    }
   },
   "id": "fb089c50e7afd12a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. MT step ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c09c5649c72610c"
  },
  {
   "cell_type": "code",
   "source": [
    "from nn_mt import Network\n",
    "from nn_mt import define_min_max\n",
    "\n",
    "# mt_dict_fn = os.path.join(parent_dir, 'data', 'exp', 'MT_pickle', 'MT52', 'dict.pkl') \n",
    "# \"D:\\mrf\\data\\exp\\MT_pickle\\MT52\\dict.pkl\"\n",
    "min_param_tensor, max_param_tensor, min_water_t1t2_tensor, max_water_t1t2_tensor = define_min_max(mt_dict_fn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T09:00:00.028862Z",
     "start_time": "2024-06-17T08:59:59.975267Z"
    }
   },
   "id": "92b1a4b114215aa3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.a. load model ###"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "137e28fb33fc7b0f"
  },
  {
   "cell_type": "code",
   "source": [
    "reco_net = Network(sched_iter).to(device)\n",
    "checkpoint = torch.load(mt_nn_fn, map_location=torch.device(device))\n",
    "reco_net.load_state_dict(checkpoint['model_state_dict'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T09:00:00.035035Z",
     "start_time": "2024-06-17T09:00:00.029420Z"
    }
   },
   "id": "1f6a46425e0c68ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.b. MT maps (protocol mt52) ##"
   ],
   "id": "219b4b87fbe1270f"
  },
  {
   "cell_type": "code",
   "source": [
    "from nn_mt import normalize_range\n",
    "\n",
    "# Normalizing according to dict water_t1t2 min and max values\n",
    "input_water_t1t2_acquired = torch.hstack((acquired_map_t1w, acquired_map_t2w))\n",
    "input_water_t1t2_acquired = normalize_range(original_array=input_water_t1t2_acquired,\n",
    "                                            original_min=min_water_t1t2_tensor,\n",
    "                                            original_max=max_water_t1t2_tensor, new_min=0, new_max=1).to(device)\n",
    "\n",
    "# adding the water_t1t2 input as two additional elements in the noised_sig vector\n",
    "acquired_data = torch.hstack((input_water_t1t2_acquired, acquired_data_52)).to(device).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T09:00:00.048429Z",
     "start_time": "2024-06-17T09:00:00.035555Z"
    }
   },
   "id": "b864700c81254d54",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.c. evaluate ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65091ea3844fae46"
  },
  {
   "cell_type": "code",
   "source": [
    "from nn_mt import un_normalize_range\n",
    "\n",
    "reco_net.eval()\n",
    "t0 = time.time()\n",
    "prediction = reco_net(acquired_data.float())\n",
    "print(f\"Prediction took {time.time() - t0:.5f} seconds\")\n",
    "\n",
    "# Un-normalizing to go back to physical units\n",
    "prediction = un_normalize_range(prediction, original_min=min_param_tensor.to(device),\n",
    "                                original_max=max_param_tensor.to(device), new_min=0, new_max=1)\n",
    "\n",
    "# print(prediction.shape)\n",
    "\n",
    "# mask = np.ones((c_acq_data, w_acq_data))\n",
    "quant_maps_mt = {}\n",
    "\n",
    "# Reshaping back to the image dimension\n",
    "quant_maps_mt['fs'] = prediction.cpu().detach().numpy()[:, 0]\n",
    "quant_maps_mt['fs'] = quant_maps_mt['fs'].T\n",
    "quant_maps_mt['fs'] = np.reshape(quant_maps_mt['fs'], (c_acq_data, w_acq_data), order='F')\n",
    "\n",
    "quant_maps_mt['ksw'] = prediction.cpu().detach().numpy()[:, 1]\n",
    "quant_maps_mt['ksw'] = quant_maps_mt['ksw'].T\n",
    "quant_maps_mt['ksw'] = np.reshape(quant_maps_mt['ksw'], (c_acq_data, w_acq_data), order='F')\n",
    "\n",
    "input_mt_param = prediction.cpu().detach().numpy()\n",
    "input_mt_param = torch.from_numpy(input_mt_param)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T09:00:00.287834Z",
     "start_time": "2024-06-17T09:00:00.049473Z"
    }
   },
   "id": "b84568efef3ee416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 0.19148 seconds\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Glu step ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d70ba2e698e7bc24"
  },
  {
   "cell_type": "code",
   "source": [
    "from nn_mt_glu import MNetwork\n",
    "from nn_mt_glu import normalize_range, un_normalize_range, define_min_max\n",
    "\n",
    "# glu_dict_fn = f\"D:\\mrf\\data\\exp\\mouse_pickle\\{107}a\\dict.pkl\"\n",
    "(min_param_tensor, max_param_tensor, min_water_t1t2_tensor, max_water_t1t2_tensor,\n",
    "     min_mt_param_tensor, max_mt_param_tensor) = define_min_max(glu_dict_fn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-17T09:00:00.288591Z"
    }
   },
   "id": "43c7364ade35b971",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.a. load model ###"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a86c65b93c50a93"
  },
  {
   "cell_type": "code",
   "source": [
    "reco_net = MNetwork(sched_iter).to(device)\n",
    "checkpoint = torch.load(glu_nn_fn, map_location=torch.device(device))\n",
    "reco_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "loss_per_epoch = checkpoint['loss_per_epoch']\n",
    "# noise_std = checkpoint['noise_std']\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "2d187b72b31b208a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting training loss\n",
    "plt.figure()\n",
    "plt.plot(loss_per_epoch[0:])\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('MSE Loss', fontsize=20)\n",
    "plt.title('Training Loss', fontsize=20)\n",
    "plt.tight_layout()  # Adjust subplot parameters to give specified padding\n",
    "plt.savefig(f'{subject_nn_image_path}/loss.jpeg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "1389cab5f9ed3f05",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.b. Glu maps (protocol 107a) ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3722a1d89b0dd623"
  },
  {
   "cell_type": "code",
   "source": [
    "# Normalizing according to dict water_t1t2 min and max values\n",
    "input_water_t1t2_acquired = torch.hstack((acquired_map_t1w, acquired_map_t2w))\n",
    "input_water_t1t2_acquired = normalize_range(original_array=input_water_t1t2_acquired,\n",
    "                                            original_min=min_water_t1t2_tensor,\n",
    "                                            original_max=max_water_t1t2_tensor, new_min=0, new_max=1).to(device)\n",
    "\n",
    "input_mt_param = normalize_range(original_array=input_mt_param,\n",
    "                                            original_min=min_mt_param_tensor,\n",
    "                                            original_max=max_mt_param_tensor, new_min=0, new_max=1).to(device)\n",
    "\n",
    "# adding the water_t1t2 input as two additional elements in the noised_sig vector\n",
    "acquired_data = torch.hstack((input_mt_param, input_water_t1t2_acquired, acquired_data_107)).to(device).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "2a13ffcbc6cd80f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.c. evaluate ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e3a2fe84a4fe293"
  },
  {
   "cell_type": "code",
   "source": [
    "reco_net.eval()\n",
    "t0 = time.time()\n",
    "prediction = reco_net(acquired_data.float())\n",
    "print(f\"Prediction took {time.time() - t0:.5f} seconds\")\n",
    "\n",
    "# Un-normalizing to go back to physical units\n",
    "prediction = un_normalize_range(prediction, original_min=min_param_tensor.to(device),\n",
    "                                original_max=max_param_tensor.to(device), new_min=0, new_max=1)\n",
    "\n",
    "# print(prediction.shape)\n",
    "\n",
    "# mask = np.ones((c_acq_data, w_acq_data))\n",
    "quant_maps_glu = {}\n",
    "\n",
    "# Reshaping back to the image dimension\n",
    "quant_maps_glu['fs'] = prediction.cpu().detach().numpy()[:, 0]\n",
    "quant_maps_glu['fs'] = quant_maps_glu['fs'].T\n",
    "quant_maps_glu['fs'] = np.reshape(quant_maps_glu['fs'], (c_acq_data, w_acq_data), order='F')\n",
    "\n",
    "quant_maps_glu['ksw'] = prediction.cpu().detach().numpy()[:, 1]\n",
    "quant_maps_glu['ksw'] = quant_maps_glu['ksw'].T\n",
    "quant_maps_glu['ksw'] = np.reshape(quant_maps_glu['ksw'], (c_acq_data, w_acq_data), order='F')\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "cd8246be69d4d6b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## plot ##"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70da5eb77fad3676"
  },
  {
   "cell_type": "code",
   "source": [
    "full_mask = subject_dict['roi_mask']\n",
    "date = subject_dict['month']\n",
    "save_name = subject_dict['save_name']\n",
    "temp = subject_dict['temp']\n",
    "highres_img_idx = subject_dict['highres_img_idx']\n",
    "# roi_center = subject_dict['roi_center']\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "92a2a7c2fef49d5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## custom color-maps ##"
   ],
   "id": "8daa87c415ef6e04"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Create custom Viridis colormap with black for 0 values\n",
    "custom_viridis = np.array(plotly.colors.sequential.Viridis)\n",
    "custom_viridis[0] = '#000000'  # Set black for 0 values\n",
    "\n",
    "# Create custom Plasma colormap with black for 0 values\n",
    "custom_plasma = np.array(plotly.colors.sequential.Plasma)\n",
    "custom_plasma[0] = '#000000'  # Set black for 0 values\n",
    "\n",
    "# Create custom Viridis colormap with black for 0 values\n",
    "custom_plotly3 = np.array(plotly.colors.sequential.Inferno)\n",
    "custom_plotly3[0] = '#000000'  # Set black for 0 values\n",
    "\n",
    "# Create custom Plasma colormap with black for 0 values\n",
    "custom_aggrnyl = np.array(plotly.colors.sequential.Electric)\n",
    "custom_aggrnyl[0] = '#000000'  # Set black for 0 values\n",
    "\n",
    "# Create custom Viridis colormap with black for 0 values\n",
    "custom_magma = np.array(plotly.colors.sequential.Magma)\n",
    "custom_magma[0] = '#000000'  # Set black for 0 values\n",
    "\n",
    "# Create custom Plasma colormap with black for 0 values\n",
    "custom_cividis = np.array(plotly.colors.sequential.Cividis)\n",
    "custom_cividis[0] = '#000000'  # Set black for 0 values\n"
   ],
   "id": "e578e15c74a82374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# t1 t2 plot #"
   ],
   "id": "59aeee3fedb08485"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create subplots with 1 row and 3 columns, increased horizontal spacing\n",
    "fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.09, subplot_titles=['t1 [ms]', 't2 [ms]'])\n",
    "\n",
    "# Add heatmaps for the three arrays\n",
    "heatmap_fs = go.Heatmap(z=t1*mask, colorscale=custom_viridis, coloraxis='coloraxis1')\n",
    "heatmap_ksw = go.Heatmap(z=t2*mask, colorscale=custom_plasma, coloraxis='coloraxis2')\n",
    "# heatmap_fs = go.Heatmap(z=t1, colorscale=custom_viridis, coloraxis='coloraxis1')\n",
    "# heatmap_ksw = go.Heatmap(z=t2, colorscale=custom_plasma, coloraxis='coloraxis2')\n",
    "\n",
    "fig.add_trace(heatmap_fs, row=1, col=1)\n",
    "fig.add_trace(heatmap_ksw, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',  # Set the theme to plotly dark\n",
    "    title_text=f\"Mouse {subject_i+1} {date} {temp}°C: t1 & t2 maps\",\n",
    "    showlegend=False,  # Hide legend\n",
    "    height=400,  # 345\n",
    "    width=800,  # Set a width based on your preference\n",
    "    margin=dict(l=10, r=40, t=60, b=20),  # Adjust top and bottom margins\n",
    "    title=dict(x=0.02, y=0.97)  # Adjust the title position\n",
    ")\n",
    "\n",
    "# Add individual titles and separate colorbars\n",
    "for i, title in enumerate(['t1', 't2'], start=1):\n",
    "    fig.update_xaxes(row=1, col=i, showgrid=False, showticklabels=False)\n",
    "    fig.update_yaxes(showgrid=False, row=1, col=i, showticklabels=False, autorange='reversed')  # Reverse the y-axis\n",
    "\n",
    "# Manually add separate colorbars\n",
    "colorbar_fs = {'colorscale': custom_viridis, 'cmin': 1100, 'cmax': 2600}\n",
    "colorbar_ksw = {'colorscale': custom_plasma, 'cmin': 30, 'cmax': 200}\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis1=colorbar_fs,\n",
    "    coloraxis2=colorbar_ksw,\n",
    "    coloraxis_colorbar=dict(x=0.45, y=0.5),\n",
    "    coloraxis2_colorbar=dict(x=1, y=0.5),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'{subject_image_path}/t1_t2.jpeg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "dda995bd2a4cbe35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# t1, t2 & MT plot #"
   ],
   "id": "2e55ad9d311163cf"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create subplots with 1 row and 3 columns, increased horizontal spacing\n",
    "fig = make_subplots(rows=1, cols=4, horizontal_spacing=0.06, subplot_titles=['t1 [ms]', 't2 [ms]', 'MT (%)', 'MT ksw [Hz]', 'Glu [mM]', 'Glu ksw [Hz]'])\n",
    "\n",
    "# Add heatmaps for the three arrays\n",
    "heatmap_t1 = go.Heatmap(z=t1*full_mask, colorscale=custom_viridis, coloraxis='coloraxis1')\n",
    "heatmap_t2 = go.Heatmap(z=t2*full_mask, colorscale=custom_plasma, coloraxis='coloraxis2')\n",
    "heatmap_mt_fs = go.Heatmap(z=quant_maps_mt['fs']*100*full_mask, colorscale=custom_viridis, coloraxis='coloraxis3')\n",
    "heatmap_mt_ksw = go.Heatmap(z=quant_maps_mt['ksw']*full_mask, colorscale=custom_plasma, coloraxis='coloraxis4')\n",
    "\n",
    "fig.add_trace(heatmap_t1, row=1, col=1)\n",
    "fig.add_trace(heatmap_t2, row=1, col=2)\n",
    "fig.add_trace(heatmap_mt_fs, row=1, col=3)\n",
    "fig.add_trace(heatmap_mt_ksw, row=1, col=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',  # Set the theme to plotly dark\n",
    "    title_text=f\"Mouse {subject_i+1} {date} {temp}°C: '52MT' NN\",\n",
    "    showlegend=False,  # Hide legend\n",
    "    height=350,  # 300\n",
    "    width=1400,  # Set a width based on your preference\n",
    "    margin=dict(l=10, r=100, t=60, b=20),  # Adjust top and bottom margins\n",
    "    title=dict(x=0.02, y=0.97)  # Adjust the title position\n",
    ")\n",
    "\n",
    "# Add individual titles and separate colorbars\n",
    "for i, title in enumerate([1, 2 ,3, 4], start=1):\n",
    "    fig.update_xaxes(row=1, col=i, showgrid=False, showticklabels=False)\n",
    "    fig.update_yaxes(showgrid=False, row=1, col=i, showticklabels=False, autorange='reversed')  # Reverse the y-axis\n",
    "\n",
    "# Manually add separate colorbars\n",
    "f_const = 3 / 110000\n",
    "colorbar_t1 = {'colorscale': custom_plotly3, 'cmin': 0, 'cmax': 2300} #, 'cmin': 0, 'cmax': f_lims[1]/f_const}\n",
    "colorbar_t2 = {'colorscale': custom_aggrnyl, 'cmin': 0, 'cmax': 110} #, 'cmin': k_lims[0], 'cmax': k_lims[1]}\n",
    "colorbar_fs = {'colorscale': custom_viridis} #, 'cmin': 0, 'cmax': f_lims[1]/f_const}\n",
    "colorbar_ksw = {'colorscale': custom_plasma} #, 'cmin': k_lims[0], 'cmax': k_lims[1]}\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis1=colorbar_t1,\n",
    "    coloraxis2=colorbar_t2,\n",
    "    coloraxis3=colorbar_fs,\n",
    "    coloraxis4=colorbar_ksw,\n",
    "    coloraxis_colorbar=dict(x=0.205, y=0.5),\n",
    "    coloraxis2_colorbar=dict(x=0.47, y=0.5),\n",
    "    coloraxis3_colorbar=dict(x=0.735, y=0.5),\n",
    "    coloraxis4_colorbar=dict(x=1, y=0.5),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'{subject_image_path}/mt_sequential_{mt_type}.jpeg')  # there are 2 types\n"
   ],
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "cda09a23ec57447e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# t1, t2, MT & Glu plot #"
   ],
   "id": "1123e484eacc5e52"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create subplots with 1 row and 3 columns, increased horizontal spacing\n",
    "fig = make_subplots(rows=3, cols=2, horizontal_spacing=0.1, vertical_spacing=0.03, \n",
    "                    subplot_titles=['t1 [ms]', 't2 [ms]', 'MT (%)', 'MT ksw [Hz]', 'Glu [mM]', 'Glu ksw [Hz]'])\n",
    "\n",
    "# Add heatmaps for the three arrays\n",
    "heatmap_fs = go.Heatmap(z=quant_maps_glu['fs']*(110000/3)*full_mask, colorscale=custom_magma, coloraxis='coloraxis5')\n",
    "heatmap_ksw = go.Heatmap(z=quant_maps_glu['ksw']*full_mask, colorscale=custom_cividis, coloraxis='coloraxis6')\n",
    "\n",
    "# r_c, c_c = roi_center\n",
    "# d = 5\n",
    "# # Extract the ROI from the image\n",
    "# roi_fs = quant_maps_glu['fs'][r_c-d:r_c+d, c_c-d:c_c+d]*(110000/3)\n",
    "# roi_ksw = quant_maps_glu['ksw'][r_c-d:r_c+d, c_c-d:c_c+d]\n",
    "# \n",
    "# mean_fs = np.mean(roi_fs)\n",
    "# roi_ksw = np.mean(roi_ksw)\n",
    "\n",
    "fig.add_trace(heatmap_t1, row=1, col=1)\n",
    "fig.add_trace(heatmap_t2, row=1, col=2)\n",
    "fig.add_trace(heatmap_mt_fs, row=2, col=1)\n",
    "fig.add_trace(heatmap_mt_ksw, row=2, col=2)\n",
    "fig.add_trace(heatmap_fs, row=3, col=1)\n",
    "fig.add_trace(heatmap_ksw, row=3, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',  # Set the theme to plotly dark\n",
    "    title_text=f\"Mouse {subject_i+1} {date} {temp}°C: '{fp_prtcl_name}' Glutamate MRF Sequential NN (noise 0.{glu_noise})\",\n",
    "    showlegend=False,  # Hide legend\n",
    "    height=1000, # 900\n",
    "    width=750,  # 900\n",
    "    margin=dict(l=10, r=40, t=80, b=20),  # Adjust top and bottom margins\n",
    "    title=dict(x=0.02, y=0.97)  # Adjust the title position\n",
    ")\n",
    "\n",
    "# Add individual titles and separate colorbars\n",
    "for i, title in enumerate([1, 2, 3], start=1):\n",
    "    fig.update_xaxes(row=i, col=1, showgrid=False, showticklabels=False)\n",
    "    fig.update_xaxes(row=i, col=2, showgrid=False, showticklabels=False)\n",
    "    fig.update_yaxes(showgrid=False, row=i, col=1, showticklabels=False, autorange='reversed')  # Reverse the y-axis\n",
    "    fig.update_yaxes(showgrid=False, row=i, col=2, showticklabels=False, autorange='reversed')  # Reverse the y-axis\n",
    "\n",
    "# Manually add separate colorbars\n",
    "f_const = 3 / 110000\n",
    "colorbar_t1 = {'colorscale': custom_plotly3, 'cmin': 0, 'cmax': 2300} #, 'cmin': 0, 'cmax': f_lims[1]/f_const}\n",
    "colorbar_t2 = {'colorscale': custom_aggrnyl, 'cmin': 0, 'cmax': 110} #, 'cmin': k_lims[0], 'cmax': k_lims[1]}\n",
    "colorbar_mt_fs = {'colorscale': custom_viridis}\n",
    "colorbar_mt_ksw = {'colorscale': custom_plasma}\n",
    "colorbar_fs = {'colorscale': custom_magma, 'cmin': 0, 'cmax': 20}\n",
    "colorbar_ksw = {'colorscale': custom_cividis, 'cmin': 0, 'cmax': 12500}\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis1=colorbar_t1,\n",
    "    coloraxis2=colorbar_t2,\n",
    "    coloraxis3=colorbar_mt_fs,\n",
    "    coloraxis4=colorbar_mt_ksw,\n",
    "    coloraxis5=colorbar_fs,\n",
    "    coloraxis6=colorbar_ksw,\n",
    "    coloraxis_colorbar=dict(x=0.45, y=0.85, len=0.3),\n",
    "    coloraxis2_colorbar=dict(x=1, y=0.85, len=0.3),\n",
    "    coloraxis3_colorbar=dict(x=0.45, y=0.5, len=0.3),\n",
    "    coloraxis4_colorbar=dict(x=1, y=0.5, len=0.3),\n",
    "    coloraxis5_colorbar=dict(x=0.45, y=0.15, len=0.3),\n",
    "    coloraxis6_colorbar=dict(x=1, y=0.15, len=0.3),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'{subject_nn_image_path}/glu_sequential.jpeg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "4b829dbbe8afc11c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Glu plot #"
   ],
   "id": "ed94180e4a02985d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Create subplots with 1 row and 3 columns, increased horizontal spacing\n",
    "fig = make_subplots(rows=2, cols=2, horizontal_spacing=0.13 , vertical_spacing=0.02, subplot_titles=['Glu [mM]', 'ksw [Hz]'], row_heights=[0.7, 0.3])\n",
    "\n",
    "fig.add_trace(heatmap_fs, row=1, col=1)\n",
    "fig.add_trace(heatmap_ksw, row=1, col=2)\n",
    "\n",
    "masked_fs = quant_maps_glu['fs'][mask == 1] * (110000/3)\n",
    "masked_ksw = quant_maps_glu['ksw'][mask == 1]\n",
    "# Add the histogram trace\n",
    "fig.add_trace(go.Histogram(x=masked_fs, nbinsx=50, marker=dict(color=custom_magma[3])), row=2, col=1)\n",
    "fig.add_trace(go.Histogram(x=masked_ksw, nbinsx=50, marker=dict(color=custom_cividis[2])), row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',  # Set the theme to plotly dark\n",
    "    title_text=f\"Mouse {subject_i+1} {date} {temp}°C: Glutamate MRF Sequential NN (noise 0.{glu_noise})\",\n",
    "    showlegend=False,  # Hide legend\n",
    "    height=510,  # 345\n",
    "    width=800,  # Set a width based on your preference\n",
    "    margin=dict(l=10, r=40, t=60, b=20),  # Adjust top and bottom margins\n",
    "    title=dict(x=0.02, y=0.97)  # Adjust the title position\n",
    ")\n",
    "\n",
    "# Add individual titles and separate colorbars\n",
    "for i, title in enumerate(['Glu [mM]', 'ksw [Hz]'], start=1):\n",
    "    fig.update_xaxes(row=1, col=i, showgrid=False, showticklabels=False)\n",
    "    fig.update_yaxes(showgrid=False, row=1, col=i, showticklabels=False, autorange='reversed')  # Reverse the y-axis\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis5=colorbar_fs,\n",
    "    coloraxis6=colorbar_ksw,\n",
    "    coloraxis5_colorbar=dict(x=0.45, y=0.5),\n",
    "    coloraxis6_colorbar=dict(x=1, y=0.5),\n",
    ")\n",
    "\n",
    "# Customize x-axis ticks for the histogram in row 2, column 2\n",
    "min_val = np.floor(np.min(masked_fs))\n",
    "max_val = np.ceil(np.max(masked_fs))\n",
    "tickvals = np.arange(min_val, max_val, 5).astype('int')\n",
    "ticktext = [str(val) for val in tickvals]\n",
    "fig.update_xaxes(row=2, col=1, tickvals=tickvals, ticktext=ticktext)\n",
    "\n",
    "# Customize x-axis ticks for the histogram in row 2, column 2\n",
    "min_val = np.floor(np.min(masked_ksw))\n",
    "max_val = np.ceil(np.max(masked_ksw))\n",
    "tickvals = np.arange(min_val, max_val, 2000).astype('int')\n",
    "ticktext = [str(val) for val in tickvals]\n",
    "fig.update_xaxes(row=2, col=2, tickvals=tickvals, ticktext=ticktext)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "pio.write_image(fig, f'{subject_nn_image_path}/glu_sequential_kf.jpeg')\n"
   ],
   "id": "b71d18191a7e8c57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "bc31d6562d280141",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
