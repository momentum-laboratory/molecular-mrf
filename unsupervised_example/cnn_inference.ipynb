{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import h5py\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import timeit\n",
    "from lib.Model_Quant import nnModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = 'data'\n",
    "dir_model = 'model'\n",
    "ds = 40\n",
    "lr = 1e-4\n",
    "gpu = 0\n",
    "dir_result = 'result'\n",
    "\n",
    "if not os.path.exists(dir_result):\n",
    "    os.mkdir(dir_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  0\n",
      "NVIDIA GeForce MX550\n",
      "Memory Usage:\n",
      "Allocated: 0.1 GB\n",
      "Cached:    0.9 GB\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "GPU_NUM = gpu # GPU number\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 40, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "## Dataset #########################################################################\n",
    "X_mat = sio.loadmat(dir_data + \"/input_invivo_test_mtcmrf_PR40.mat\")\n",
    "test_X = X_mat['input_invivo_test']\n",
    "\n",
    "X_test=torch.FloatTensor(test_X)\n",
    "\n",
    "print(np.shape(test_X))\n",
    "\n",
    "#####################################################################################\n",
    "testset = TensorDataset(X_test)\n",
    "testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "\n",
    "## Model loading - Trained model #####\n",
    "cnn = nnModel(ds,device)\n",
    "PATH=dir_model+'/NN_model_UL.pth'\n",
    "checkpoint=torch.load(PATH,map_location=device)\n",
    "cnn.load_state_dict(checkpoint)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "TEST_DATASIZE = X_test.shape[0]\n",
    "quantification_result=torch.zeros([TEST_DATASIZE,4,256,256],device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised pipeline inference took: 10.290169042011257 s\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "with torch.no_grad(): # important!\n",
    "    test_loss = 0.0\n",
    "    for j, data in enumerate(testloader):\n",
    "        [X_batch]=data\n",
    "        X_batch = X_batch.to(device)\n",
    "                        \n",
    "        x_pred_test = cnn(X_batch)\n",
    "        quantification_result[j,:,:,:]=x_pred_test\n",
    "\n",
    "    quantification_result=quantification_result.cpu()\n",
    "    quantification_result=quantification_result.numpy()\n",
    "\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Unsupervised pipeline inference took: \" + str(elapsed) + \" s\")\n",
    "    sio.savemat(dir_result+'/quantification_UL.mat',{'result_nn': quantification_result})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
